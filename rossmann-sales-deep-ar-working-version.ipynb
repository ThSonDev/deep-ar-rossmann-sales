{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1582744,"sourceType":"datasetVersion","datasetId":936050}],"dockerImageVersionId":29860,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## 1 - Install/Upgrade and import required libraries","metadata":{}},{"cell_type":"code","source":"# Install gluon ts from master-branch to fix error in Negative Binomial Distribution\n%pip install git+https://github.com/awslabs/gluon-ts.git\n%pip install --upgrade pandas==1.0\n%pip install --upgrade mxnet==1.6","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\nimport mxnet as mx\nfrom mxnet import gluon\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport json\nimport os\nfrom tqdm.autonotebook import tqdm\nfrom pathlib import Path","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2 - Select prediction length, input path and validation\n#### If validation is True, the last prediction_length time points of the training set will be used as the testing set, to perform hyper-parameter tuning.","metadata":{}},{"cell_type":"code","source":"validation = True\n\nprediction_length = 48\n\nPATH=\"../input/rossmann-prepared-dataset\"","metadata":{"_uuid":"bddc1522-11c4-4697-a1f8-94b5c9aaec11","_cell_guid":"4fd6b8f7-ef3d-4f42-91d7-001f4427d082","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3 - Load and display data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(f'{PATH}/rossmann_train.csv')\npd.set_option('display.max_columns', 50)\npd.set_option('display.max_rows', 1000)\ndf.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4 - Feature engineering, data cleaning and analysis\n### 4.1 - Convert categoricals to numerical\n* Convert every categorical feature that we include in dynamic_features to a numerical value.\n* Store category code value in a new feature called 'feature-name_cat'.","metadata":{}},{"cell_type":"code","source":"# Select categorical variables\ncat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n\n# Make sure they are all of type category\nfor v in cat_vars: df[v] = df[v].astype('category').cat.as_ordered()\n\n# Add column to dataframe with value of 'category.code'\nfor v in cat_vars: \n    df[v+'_cat'] = df[v].cat.codes    \n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.2 - Count number of time series and time points per serie\n#### Since we have the daily sales of each store, each time series is identified by the store id.","metadata":{}},{"cell_type":"code","source":"# Get number of time series\nnumber_ts=len(df.Store.unique())\nprint('Number of time series:\\n', number_ts)\n\n# Get number of timepoints in each time serie\nprint('List of time series lengths:\\n',df['Store'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Check how many time series there are with the maximum number of time points","metadata":{}},{"cell_type":"code","source":"ts_length = max(df['Store'].value_counts())\n\ncountEqual = 0\ncountOver = 0\ncountUnder = 0\n\n# Check how many time series have length equal to ts_length\nfor v in df['Store'].value_counts():\n    if(v == ts_length):\n        countEqual += 1\n        \n# Check how many time series have length over ts_length\nfor v in df['Store'].value_counts():\n    if(v > ts_length):\n        countOver += 1\n        \n# Check how many time series have length under ts_length\nfor v in df['Store'].value_counts():\n    if(v < ts_length):\n        countUnder += 1\n        \ncountEqualPercentage = round(100*countEqual/number_ts,1)\ncountOverPercentage = round(100*countOver/number_ts,1)\ncountUnderPercentage = round(100*countUnder/number_ts,1)\n\nprint(f'Time series with {ts_length} time-points: {countEqual} ({countEqualPercentage}%)\\nTime series with more than {ts_length} time-points: {countOver} ({countOverPercentage}%)\\nTime series with less than {ts_length} time-points: {countUnder} ({countUnderPercentage}%)')\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 4.3 - Remove Time Series with missing values\n#### We can see that out of our 1115 time series, 181 (16%) have missing values, some of them for over 150 time points, this can negatively impact our models ability to make accurate predictions, so we will remove them","metadata":{}},{"cell_type":"code","source":"# Remove Stores with missing dates, sort by Date and Store\n\ndf = df.groupby('Store').filter(lambda x : len(x)==ts_length)\ndf = df.sort_values(['Date','Store'])\npd.set_option('display.max_columns', 90)\n\n#remove unnamed leftover column from index\ndf.columns.str.match('Unnamed')\n# array([ True, False, False, False])\n\ndf=df.loc[:, ~df.columns.str.match('Unnamed')]\n# Display data\ndf.head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5 - Prepare data\n### 5.1 - Build target values (sales) list","metadata":{}},{"cell_type":"code","source":"# Update number of ts\nnumber_ts = len(df.Store.unique())\n\nstack = df.iloc[0:number_ts].Sales\ncount = number_ts\n\nfor i in range(ts_length-1):\n    curr_idx = count + number_ts\n    stack = np.column_stack((stack, df.iloc[count:curr_idx].Sales))\n    count += number_ts\n\ntest_target_values = stack.copy()\ntrain_target_values = test_target_values[:,:-prediction_length]\n    \n# Validation\n\n# Use the prediction_length days prior to the days used for \n# testing as the test set to perform hyper-parameter tuning\n\n# training-set-length = ts_length - prediction_length*2\n# testing-set-length = ts_length - prediction_length\nif(validation):\n    test_target_values = test_target_values[:,:-prediction_length]\n    train_target_values = test_target_values[:,:-prediction_length]\n\n# Ensure target values list has the correct shape (number_ts, ts_length)\n# number_ts - number of time series | ts_length - time series length\nprint('Expected shape: (number_ts, ts_length)\\n')\nprint(f'Number of time series: {number_ts}\\nTime series length: {ts_length}\\n')\nprint(f'Target testing values shape: {test_target_values.shape} \\nTarget training values shape (excluding last {prediction_length} time steps): {train_target_values.shape}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.2 - Build dynamic features list\n#### We will create several sets of dynamic features to assess their impact on the performance","metadata":{}},{"cell_type":"code","source":"# Dynamic features - Open\ndynamic_features_open = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat', 'State_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n     'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h','CloudCover', 'Events_cat','StateHoliday', 'SchoolHoliday',\n     'CompetitionDistance', 'trend', 'trend_DE', 'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat', 'StateHoliday_cat', 'CompetitionMonthsOpen_cat', 'Promo2Weeks_cat', 'PromoInterval_cat', 'CompetitionOpenSinceYear_cat', 'Promo2SinceYear',\n     'Week_cat', 'Promo_fw_cat', 'Promo_bw_cat', 'StateHoliday_fw_cat', 'StateHoliday_bw_cat', 'SchoolHoliday_fw_cat','SchoolHoliday_bw_cat', 'Promo2SinceYear_cat'],\n    axis=1\n)\n\n# Dynamic features - Open / Promotions\ndynamic_features_open_promo = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat', 'State_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n     'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h','CloudCover', 'Events_cat','StateHoliday', 'SchoolHoliday',\n     'CompetitionDistance', 'trend', 'trend_DE', 'AfterStateHoliday', 'BeforeStateHoliday', 'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat', 'StateHoliday_cat', 'CompetitionMonthsOpen_cat', 'CompetitionOpenSinceYear_cat',\n     'Week_cat', 'StateHoliday_fw_cat', 'StateHoliday_bw_cat', 'SchoolHoliday_fw_cat','SchoolHoliday_bw_cat'],\n    axis=1\n)\n\n# Dynamic features - Open / Promotions / Holidays\ndynamic_features_open_promo_holidays = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'CompetitionMonthsOpen',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat', 'State_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n     'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h','CloudCover', 'Events_cat',\n     'CompetitionDistance', 'trend', 'trend_DE', 'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat', 'CompetitionMonthsOpen_cat', 'CompetitionOpenSinceYear_cat',\n     'Week_cat', 'StateHoliday', 'SchoolHoliday'],\n    axis=1\n)\n\n# Dynamic features - Open / Promotions / Holidays / Competition Distance\ndynamic_features_open_promo_holidays_competition = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat', 'State_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC', 'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', \n     'Max_Wind_SpeedKm_h', 'Mean_Wind_SpeedKm_h','CloudCover', 'Events_cat',\n     'trend', 'trend_DE', 'DayOfWeek_cat', 'Year_cat', 'Month_cat', \n     'Day_cat','CompetitionMonthsOpen_cat', 'CompetitionOpenSinceYear','CompetitionOpenSinceYear_cat',\n     'Week_cat', 'StateHoliday', 'SchoolHoliday'],\n    axis=1\n)\n\n# Dynamic features - Open / Promotions / Holidays / Competition / Weather\ndynamic_features_open_promo_holidays_competition_weather = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'CompetitionMonthsOpen_cat','Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat', 'State_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'trend', 'trend_DE', 'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat',\n     'Week_cat', 'StateHoliday', 'SchoolHoliday'],\n    axis=1\n)\n\n# Dynamic features - Open / Promotions / Holidays / Competition / Weather / Google Trend\ndynamic_features_open_promo_holidays_competition_weather_googletrend = df.drop(\n    ['Sales', 'Date', 'Store', 'DayOfWeek', 'Year', 'Month', 'Day' ,'CompetitionMonthsOpen_cat',\n     'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat', 'Assortment_cat', 'StoreType_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat',\n     'Week_cat', 'StateHoliday', 'SchoolHoliday'],\n    axis=1\n)\n\n# Display complete dynamic_features set\npd.set_option('display.max_rows', 30)\ndynamic_features_open_promo_holidays_competition_weather_googletrend.head(30)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Building Dynamic Features for Rossmann\n\ndynamic_features = dynamic_features_open_promo_holidays_competition_weather_googletrend\n\nstack = [dynamic_features.iloc[0:number_ts,1:].values.T]\ncount = number_ts\n\nfor i in range(ts_length-1):\n    curr_idx = count + number_ts\n    stack = np.vstack((stack, [dynamic_features.iloc[count:curr_idx,1:].values.T]))\n    count += number_ts\n    \ntest_dynamic_features_list = stack.T\n\n# Remove the last <prediction_length> days from the training set\ntrain_dynamic_features_list = stack[:-prediction_length].T\n\n# Validation\n\n# Use the prediction_length days prior to the days used for \n# testing as the test set to perform hyper-parameter tuning\n\n# training-set-length = ts_length - prediction_length*2\n# testing-set-length = ts_length - prediction_length\nif(validation):\n    test_dynamic_features_list = stack[:-prediction_length].T\n    train_dynamic_features_list = stack[:-2*prediction_length].T\n\n# Get number of features\nnumber_ft = len(train_dynamic_features_list[0])\n\n# Ensure dynamic features list has the correct shape (number_ts, number_ft, ts_length)\n# number_ts - number of time series | number_ft - number of features | ts_length - time series length \nprint('Expected shape: (number_ts, number_features, ts_length)\\n')\nprint(f'Number of time series: {number_ts} \\nNumber of features: {number_ft}\\nTime series length: {ts_length}\\n')\nprint(f'Testing dynamic features shape: {test_dynamic_features_list.shape} \\nTraining dynamic features shape (excluding last {prediction_length} time steps): {train_dynamic_features_list.shape}')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.3 - Build static features list","metadata":{}},{"cell_type":"code","source":"# Building Static Features for Rossmann\n\nstores = df[\"Store_cat\"]\nassortments = df[\"Assortment_cat\"]\nstore_types = df[\"StoreType_cat\"]\nstates = df[\"State_cat\"]\n\ncat_features_cols = [stores, assortments, store_types, states]\ncat_features = pd.concat(cat_features_cols, axis=1)\ncat_features = cat_features.iloc[0:number_ts]\n\nstores = cat_features[\"Store_cat\"].values\nstores_un , store_counts = np.unique(stores, return_counts=True)\n\nassortments = cat_features[\"Assortment_cat\"].values\nassortments_un , assortments_counts = np.unique(assortments, return_counts=True)\n\nstore_types = cat_features[\"StoreType_cat\"].values\nstore_types_un , store_types_counts = np.unique(store_types, return_counts=True)\n\nstates = cat_features[\"State_cat\"].values\nstates_un , states_counts = np.unique(states, return_counts=True)\n\nstat_cat_list = [stores, assortments, store_types, states]\n\nstat_cat = np.concatenate(stat_cat_list)\n\nstat_cat = stat_cat.reshape(len(stat_cat_list), len(stores)).T\nstat_cat_cardinalities = [len(stores_un), len(assortments_un), len(store_types_un), len(states_un)]\n\n# Ensure static categories list has the correct shape (nt, nc)\n# nt - number of time series (934 stores) | number_cats - number of categories (4)\nprint('Expected shape: (number_ts, number_cat)\\n')\nprint(f'Number of time series: {number_ts} \\nNumber of categories: {len(stat_cat_cardinalities)}\\n')\nprint(f'Static categories shape: {stat_cat.shape}\\n')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.4 - Build date list","metadata":{}},{"cell_type":"code","source":"# Building date list for Rossmann\n\ndates = df.sort_values(['Store','Date'])\n\ndates_df = dates['Date']\ndates_df = dates_df.iloc[0:ts_length]\ndates = dates_df.iloc[0:ts_length].values\n\nfor i in range(len(dates)):\n    dates[i] = pd.Timestamp(dates[i])\n    \n\n\n# Validation\n\n# Use the prediction_length days prior to the days used for \n# testing as the test set to perform hyper-parameter tuning\nif(validation):\n    dates = dates[:-prediction_length]\n    dates_df = dates_df[:-prediction_length]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.5 - Build training and testing set","metadata":{}},{"cell_type":"code","source":"# Build training and testing set from target values and both static and dynamic features for Rossmann\n\nfrom gluonts.dataset.common import load_datasets, ListDataset\nfrom gluonts.dataset.field_names import FieldName\n\ntrain_ds = ListDataset([\n    {\n        FieldName.TARGET: target,\n        FieldName.START: start,\n        FieldName.FEAT_DYNAMIC_REAL: fdr,\n        FieldName.FEAT_STATIC_CAT: fsc\n    }\n    for (target, start, fdr, fsc) in zip(train_target_values,\n                                         dates,\n                                         train_dynamic_features_list,\n                                         stat_cat)\n], freq=\"D\")\n\ntest_ds = ListDataset([\n    {\n        FieldName.TARGET: target,\n        FieldName.START: start,\n        FieldName.FEAT_DYNAMIC_REAL: fdr,\n        FieldName.FEAT_STATIC_CAT: fsc\n    }\n    for (target, start, fdr, fsc) in zip(test_target_values,\n                                         dates,\n                                         test_dynamic_features_list,\n                                         stat_cat)\n], freq=\"D\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.6 - Check if sets are in the right format","metadata":{}},{"cell_type":"code","source":"# This will throw an error if something is wrong, otherwise it will print\nprint(f'{next(iter(train_ds))}\\n {next(iter(test_ds))}')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6 - Training Deep AR Model\n#### We will be using the Negative Binomial Distribution","metadata":{}},{"cell_type":"code","source":"from gluonts.model.deepar import DeepAREstimator\nfrom gluonts.distribution.neg_binomial import NegativeBinomialOutput\nfrom gluonts.trainer import Trainer\n\n#deepAR_estimator = DeepAREstimator(\n#    prediction_length=prediction_length,\n#    context_length=2*prediction_length,\n#    freq=\"D\",\n#    num_layers=5,\n#    num_cells=40,\n#    distr_output = NegativeBinomialOutput(),\n#    use_feat_dynamic_real=True,\n#    use_feat_static_cat=True,\n#    cardinality=stat_cat_cardinalities,\n#    dropout_rate=0.1,\n#    trainer=Trainer(\n#        learning_rate=1e-3,\n#        epochs=15,\n#        num_batches_per_epoch=500,\n#        batch_size=32\n#    )\n#)\n#\n\ndeepAR_estimator = DeepAREstimator(\n    prediction_length=prediction_length,\n    context_length=2*prediction_length,\n    freq=\"D\",\n    num_layers=5,\n    num_cells=40,\n    distr_output = NegativeBinomialOutput(),\n    use_feat_dynamic_real=True,\n    use_feat_static_cat=True,\n    cardinality=stat_cat_cardinalities,\n    dropout_rate=0.1,\n    trainer=Trainer(\n        learning_rate=1e-3,\n        epochs=20,\n        num_batches_per_epoch=400,\n        batch_size=32\n    )\n)\n\ndeepAR_predictor = deepAR_estimator.train(train_ds)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Generating forecasts\n\nOnce the estimator is fully trained, we can generate predictions from it for the test values.","metadata":{"_uuid":"222a55ad-3c40-4db6-baed-4ace8f928567","_cell_guid":"38428be6-07a5-4bcb-bc43-fdff4b368363","trusted":true}},{"cell_type":"code","source":"from gluonts.evaluation.backtest import make_evaluation_predictions\n\nforecast_it, ts_it = make_evaluation_predictions(\n    dataset=test_ds,\n    predictor=deepAR_predictor,\n    num_samples=100\n)\n\nprint(\"Obtaining time series conditioning values ...\")\ntss = list(tqdm(ts_it, total=len(test_ds)))\nprint(\"Obtaining time series predictions ...\")\nforecasts = list(tqdm(forecast_it, total=len(test_ds)))","metadata":{"_uuid":"2e01698e-b938-4bc2-b770-7ecb602ce32b","_cell_guid":"8bc429ad-aad7-4d85-8ffa-aae635d50670","trusted":true,"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Evaluation\n### 8.1 - Define evaluator","metadata":{}},{"cell_type":"code","source":"from gluonts.evaluation import Evaluator\n\nclass MyEvaluator(Evaluator):\n\n    def get_metrics_per_ts(self, time_series, forecast):\n        successive_diff = np.diff(time_series.values.reshape(len(time_series)))\n        successive_diff = successive_diff ** 2\n        successive_diff = successive_diff[:-prediction_length]\n        denom = np.mean(successive_diff)\n        pred_values = forecast.samples.mean(axis=0)\n        true_values = time_series.values.reshape(len(time_series))[-prediction_length:]\n        num = np.mean((pred_values - true_values)**2)\n        rmsse = num / denom\n        metrics = super().get_metrics_per_ts(time_series, forecast)\n        metrics[\"RMSSE\"] = rmsse\n        \n        return metrics\n\n    def get_aggregate_metrics(self, metric_per_ts):\n        wrmsse = metric_per_ts[\"RMSSE\"].mean()\n        agg_metric , _ = super().get_aggregate_metrics(metric_per_ts)\n        agg_metric[\"MRMSSE\"] = wrmsse\n        return agg_metric, metric_per_ts\n\nevaluator = MyEvaluator(quantiles=[0.5, 0.67, 0.8, 0.95, 0.99])","metadata":{"_uuid":"9d78108c-4b14-49e7-bafa-195e8c30b830","_cell_guid":"9c579795-2f12-425a-89ec-d4b290aa2f5e","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 8.2 - Generate and display metrics","metadata":{}},{"cell_type":"code","source":"agg_metrics_deepAR, item_metrics_deepAR = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n\ndf_metrics = pd.DataFrame.from_dict(agg_metrics_deepAR, orient='index').rename(columns={0: \"DeepAR\"})\n\npd.options.display.float_format = \"{:,.6f}\".format\n\ndf_metrics.loc[[\"MASE\",\"MAPE\",\"sMAPE\", \"MSIS\",  \"RMSE\", \"NRMSE\", \"MRMSSE\", \"ND\"]]\n#df_metrics_2 = df_metrics.loc[['MAE', 'sMAPE', 'RMSE', 'NRMSE']]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 9 - Plot predictions","metadata":{}},{"cell_type":"code","source":"# Number of time series to plot\n\nnumber_plots = 3\n\nplot_log_path = \"./plots/\"\ndirectory = os.path.dirname(plot_log_path)\nif not os.path.exists(directory):\n    os.makedirs(directory)\n    \ndef plot_prob_forecasts(ts_entry, forecast_entry, path, sample_id, inline=True):\n    plot_length = 200\n    prediction_intervals = (50,95)\n    legend = [\"observations\", \"median prediction\"] + [f\"{k}% prediction interval\" for k in prediction_intervals][::-1]\n\n    _, ax = plt.subplots(1, 1, figsize=(10, 5))\n    ts_entry[-plot_length:].plot(ax=ax)\n    forecast_entry.plot(prediction_intervals=prediction_intervals, color='g')\n    ax.axvline(ts_entry.index[-prediction_length], color='r')\n    plt.legend(legend, loc=\"upper left\")\n    ax.set_ylim([-500,20000])\n    if inline:\n        plt.show()\n        plt.clf()\n    else:\n        plt.savefig('{}forecast_{}.pdf'.format(path, sample_id))\n        plt.close()\n\nprint(\"Plotting time series predictions ...\")\nfor i in tqdm(range(number_plots)):\n    ts_entry = tss[i]\n    forecast_entry = forecasts[i]\n    plot_prob_forecasts(ts_entry, forecast_entry, plot_log_path, i)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 10 - Train more machine learning models for comparison\n### 10.1 - Simple Feed Forward","metadata":{}},{"cell_type":"code","source":"from gluonts.model.simple_feedforward import SimpleFeedForwardEstimator\nfrom gluonts.trainer import Trainer\n\n\nsff_estimator = SimpleFeedForwardEstimator(\n    num_hidden_dimensions=[10],\n    prediction_length=prediction_length,\n    context_length=2*prediction_length,\n    freq='1D',\n    trainer=Trainer(\n                    epochs=10,\n                    learning_rate=1e-3,\n                    hybridize=False,\n                    num_batches_per_epoch=100\n                   )\n)\n\nsff_predictor = sff_estimator.train(train_ds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"forecast_it, ts_it = make_evaluation_predictions(\n    dataset=test_ds,\n    predictor=sff_predictor,\n    num_samples=100\n)\n\nprint(\"Obtaining time series conditioning values ...\")\ntss = list(tqdm(ts_it, total=len(test_ds)))\nprint(\"Obtaining time series predictions ...\")\nforecasts = list(tqdm(forecast_it, total=len(test_ds)))\n\nagg_metrics_sff, item_metrics_sff = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n\ndf_metrics = pd.DataFrame.join(\n    df_metrics,\n    pd.DataFrame.from_dict(agg_metrics_sff, orient='index').rename(columns={0: \"Simple Feed Forward\"})\n)\ndf_metrics.loc[[\"MASE\",\"MAPE\",\"sMAPE\", \"MSIS\",  \"RMSE\", \"NRMSE\", \"MRMSSE\", \"ND\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 10.2 - Seasonal Naive","metadata":{}},{"cell_type":"code","source":"from gluonts.model.seasonal_naive import SeasonalNaivePredictor\n\nseasonal_predictor = SeasonalNaivePredictor(\n    freq=\"1D\", \n    prediction_length=48, \n    season_length=7)\n\nforecast_it, ts_it = make_evaluation_predictions(test_ds, predictor=seasonal_predictor, num_samples=100)\nprint(\"Obtaining time series conditioning values ...\")\ntss = list(tqdm(ts_it, total=len(test_ds)))\nprint(\"Obtaining time series predictions ...\")\nforecasts = list(tqdm(forecast_it, total=len(test_ds)))\n\n\nagg_metrics_seasonal, item_metrics_seasonal = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n\ndf_metrics = pd.DataFrame.join(\n    df_metrics,\n    pd.DataFrame.from_dict(agg_metrics_seasonal, orient='index').rename(columns={0: \"Seasonal naive\"})\n)\ndf_metrics.loc[[\"MASE\",\"MAPE\",\"sMAPE\", \"MSIS\",  \"RMSE\", \"NRMSE\", \"MRMSSE\", \"ND\"]]\n#df_metrics.loc[[\"MAE\", \"sMAPE\", \"MSIS\",  \"RMSE\", \"NRMSE\", \"MRMSSE\", \"ND\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 11 - Time series selection for single-time series models\n### 11.1 - Data analysis\n#### To select which time series to use in our models that only train on a single time series (so that we can compare the results with Deep AR's global model) we will perform some data analysis: \n* First we will box plot our the median of the daily sales for each store","metadata":{}},{"cell_type":"code","source":"maximums = []\nmedians = []\naverages = []\nminimums = []\n\nfor i in range(len(train_target_values)):\n    medians.append(np.median(train_target_values[i]))\n    maximums.append(max(train_target_values[i]))\n    averages.append(np.average(train_target_values[i]))\n    minimums.append(min(train_target_values[i]))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"store_idxs = np.array(range(0,len(df.Store.unique())))\nmedians = np.array(medians)\ndf_idxs = pd.DataFrame(data=store_idxs, columns=['store'])\ndf_md = pd.DataFrame(data=medians, columns=['median'])\ndf_avg = pd.DataFrame(data=averages, columns=['average'])\ndf_max = pd.DataFrame(data=maximums, columns=['maximum'])\ndf_min = pd.DataFrame(data=minimums, columns=['minimum'])\n\nstats = [df_idxs, df_md, df_avg, df_max, df_min]\n\ndf_stats = pd.concat(stats, axis = 1, ignore_index=True).rename(columns={0:\"store_idx\", 1:\"median\",2:\"average\",3:\"maximum\",4:\"minimum\"})\ndf_stats.head(5)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import plotly.express as px\n\nfig = px.box(df_stats, y='median',\n             notched=True, # used notched shape\n             title=\"Box plot daily sales median by store\",\n             hover_data=['store_idx','average','maximum','minimum'], # add store_idx column to hover data,\n             points='all'\n            )\nfig.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select 4 time series of each median quartil\n\n# Lowest median group (between 2013 and 4677)\nq1_idxs=[157, 453, 697, 701]\n\n# Second lowest median group (between 4677 and 5868)\nq2_idxs=[177,401,112, 676]\n\n#(between 5868 and 7155)\nq3_idxs=[850, 130, 384, 113]\n\n#(between 7155 and 10647)\nq4_idxs=[639, 355, 691, 360]\n\n# Select first time serie \n#ts_target_values = test_target_values[0]\n\n# Get target values\n#ts_train_values = ts_target_values[:-prediction_length]\n#ts_test_values = ts_target_values.Sales[-prediction_length:]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12 - Single-time series models\n### 12.1 - Prophet\n#### 12.1.1 - Install and import Prophet\n","metadata":{}},{"cell_type":"code","source":"#%pip install fbprophet\nfrom fbprophet import Prophet","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 12.1.2 - Prepare data for Prophet\nEach time series will be store in a dataframe containing the date and the target value (sales)","metadata":{}},{"cell_type":"code","source":"df = df.sort_values(['Store','Date'])\n\nts_test_list = []\nts_train_list = []\n\nfor i in range(0,number_ts):\n    curr_idx = i * ts_length\n    ts = df.iloc[curr_idx:curr_idx+ts_length]\n    ts = ts.drop(['StoreType', 'Assortment', 'DayOfWeek', 'Year', 'Month', 'Day' ,'CompetitionMonthsOpen_cat',\n     'Promo2Weeks', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n     'State', 'Week', 'Events', 'Store_cat',\n     'SchoolHoliday_fw','SchoolHoliday_bw', 'StateHoliday_fw', 'StateHoliday_bw', 'Promo_bw', 'Promo_fw', \n     'DayOfWeek_cat', 'Year_cat', 'Month_cat',\n     'Day_cat','Week_cat', 'StateHoliday', 'SchoolHoliday'],axis=1)\n    ts = ts.rename(columns={\"Date\": \"ds\", \"Sales\": \"y\", \"trend\": \"gtrend\"})\n    ts['ds'] = pd.to_datetime(ts['ds']) # convert date to datetime\n    cols = ['ds'] + ['y']  + [col for col in ts if (col != 'ds' and col !='y')]\n    ts = ts[cols]\n    if validation:\n        ts = ts[:-prediction_length]\n    ts_test = ts[-prediction_length:]\n    ts_train = ts[:-prediction_length]\n    ts_test_list.append(ts_test)\n    ts_train_list.append(ts_train)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_test_dates = pd.Series(dates_df, name='ds')\nts_test_dates = ts_test_dates.iloc[-prediction_length:]\nts_test_dates.reset_index(drop=True, inplace=True)\n\nts_train_dates = pd.Series(dates_df[:-prediction_length], name='ds')\nts_train_dates.reset_index(drop=True, inplace=True)\n\n\n\nts_test_list = []\nts_train_list = []\n\nfor v in test_target_values:\n    \n    ts_test_target = pd.Series(v[-prediction_length:])\n    ts_test_target.reset_index(drop=True, inplace=True)\n    \n    ts_train_target = pd.Series(v[:-prediction_length])\n    ts_train_target.reset_index(drop=True, inplace=True)\n    \n    ts_test = pd.concat([ts_test_dates, ts_test_target], axis=1)\n    ts_train = pd.concat([ts_train_dates, ts_train_target], axis=1)\n    \n    ts_test.rename(columns = {'Date':'ds'}, inplace = True) \n    ts_test.rename(columns = {0:'y'}, inplace = True) \n    ts_train.rename(columns = {'Date':'ds'}, inplace = True) \n    ts_train.rename(columns = {0:'y'}, inplace = True) \n    ts_test_list.append(ts_test)\n    ts_train_list.append(ts_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q1_list=[]\nq2_list=[]\nq3_list=[]\nq4_list=[]\n\n# Create q1 list\nfor idx in q1_idxs:\n    q1_list.append([ts_train_list[idx],ts_test_list[idx]])\n# Create q2 list\nfor idx in q2_idxs:\n    q2_list.append([ts_train_list[idx],ts_test_list[idx]])\n# Create q3 list\nfor idx in q3_idxs:\n    q3_list.append([ts_train_list[idx],ts_test_list[idx]])\n# Create q4 list\nfor idx in q4_idxs:\n    q4_list.append([ts_train_list[idx],ts_test_list[idx]])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 10.3.3 - Train the model, plot predictions and display error metrics","metadata":{}},{"cell_type":"code","source":"# Define some common error metrics\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math\n\ndef _naive_forecasting(actual: np.ndarray, seasonality: int = 1):\n    return actual[:-seasonality]\n\ndef smape(actual, predicted):\n    return 100/len(actual) * np.sum(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n\ndef rmse(actual: np.ndarray, predicted: np.ndarray):\n    return np.sqrt(mean_squared_error(actual,predicted))\n\ndef nrmse(actual: np.ndarray, predicted: np.ndarray):\n    return rmse(actual, predicted) / (actual.max() - actual.min())\n\ndef mase(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n    return mae(actual, predicted) / mae(actual[seasonality:], _naive_forecasting(actual, seasonality))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create forecast list\nq1_metrics = []\nstore_idx_idx = 0\n# Train model, generate and plot forecasts for every TS in q1\n\nfor ts in q1_list:\n    \n    # Create model\n    m = Prophet(interval_width=0.95)\n    ts_train = ts[0]\n    ts_test = ts[1]\n    \n    # Add all features\n    for col in ts_train.columns:\n        if(col != 'ds' and col != 'y'):\n            m.add_regressor(col)\n    \n    # Train model\n    #m.add_regressor('Open')\n    m.fit(ts_train)\n\n    pd.plotting.register_matplotlib_converters()\n    \n    # Get predictions\n    ts_test_forecast = m.predict(ts_test)\n    \n    # Get metrics\n    MAE = mean_absolute_error(ts_test['y'],ts_test_forecast['yhat'])\n    #MASE = mase(ts_test['y'],test_forecast['yhat'])                            \n    MSE = mean_squared_error(ts_test['y'],ts_test_forecast['yhat'])\n    sMAPE = smape(ts_test['y'],ts_test_forecast['yhat'])\n    RMSE = rmse(ts_test['y'],ts_test_forecast['yhat'])\n    NRMSE = nrmse(ts_test['y'],ts_test_forecast['yhat'])\n    \n    # Get store idx\n    store_idx = q1_idxs[store_idx_idx]\n    store_idx_idx= store_idx_idx+1\n    \n    # Store metrics in df\n    prophet_metrics = pd.DataFrame({f'Prophet_store[{store_idx}]': [MSE, sMAPE, RMSE, NRMSE]},\n                      index=['MSE', 'sMAPE', 'RMSE', 'NRMSE'])\n    q1_metrics.append(prophet_metrics)\n    \n    # Plot predictions and observed values\n    pd.plotting.register_matplotlib_converters()\n    \n    ts_test_forecast = m.predict(ts_test)\n    f, ax = plt.subplots(1)\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ax.scatter(ts_test.ds, ts_test['y'], color='r')\n    fig = m.plot(ts_test_forecast, ax=ax)\n    \n    # Zoom in on predicts\n    f, ax = plt.subplots(figsize=(14,5))\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ts_test.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)\n    ts_test_forecast.plot(kind='line',x='ds',y='yhat', color='blue',label='Forecast', ax=ax)\n    plt.title(f'Forecast vs Actuals in Store {store_idx}')\n    plt.show()\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q1_metrics_df = pd.concat(q1_metrics, axis=1)\nq1_metrics_df['mean'] = q1_metrics_df.mean(axis=1)\nq1_metrics_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q1_metrics_df = pd.concat(q1_metrics, axis=1)\nq1_metrics_df['mean'] = q1_metrics_df.mean(axis=1)\nq1_metrics_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Repeat the process for q2, q3 and q4 time series","metadata":{}},{"cell_type":"code","source":"# Create forecast list\nq2_metrics = []\nstore_idx_idx = 0\n\n# Train model, generate and plot forecasts for every TS in q1\nfor ts in q2_list:\n    \n    # Train the model\n    m = Prophet(interval_width=0.95)\n    ts_train = ts[0]\n    ts_test = ts[1]\n    m.fit(ts_train)\n\n    pd.plotting.register_matplotlib_converters()\n    \n    # Get predictions\n    ts_test_forecast = m.predict(ts_test)\n    \n    # Get metrics\n    MAE = mean_absolute_error(ts_test['y'],ts_test_forecast['yhat'])\n    #MASE = mase(ts_test['y'],test_forecast['yhat'])                            \n    MSE = mean_squared_error(ts_test['y'],ts_test_forecast['yhat'])\n    sMAPE = smape(ts_test['y'],ts_test_forecast['yhat'])\n    RMSE = rmse(ts_test['y'],ts_test_forecast['yhat'])\n    NRMSE = nrmse(ts_test['y'],ts_test_forecast['yhat'])\n    \n    # Get store idx\n    store_idx = q2_idxs[store_idx_idx]\n    store_idx_idx= store_idx_idx+1\n    \n    # Store metrics in df\n    prophet_metrics = pd.DataFrame({f'Prophet_store[{store_idx}]': [MSE, sMAPE, RMSE, NRMSE]},\n                      index=['MSE', 'sMAPE', 'RMSE', 'NRMSE'])\n    q2_metrics.append(prophet_metrics)\n    \n    # Plot predictions and observed values\n    pd.plotting.register_matplotlib_converters()\n    \n    ts_test_forecast = m.predict(ts_test)\n    f, ax = plt.subplots(1)\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ax.scatter(ts_test.ds, ts_test['y'], color='r')\n    fig = m.plot(ts_test_forecast, ax=ax)\n    \n    # Zoom in on predicts\n    f, ax = plt.subplots(figsize=(14,5))\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ts_test.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)\n    ts_test_forecast.plot(kind='line',x='ds',y='yhat', color='blue',label='Forecast', ax=ax)\n    plt.title(f'Forecast vs Actuals in Store {store_idx}')\n    plt.show()\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q2_metrics_df = pd.concat(q2_metrics, axis=1)\nq2_metrics_df['mean'] = q2_metrics_df.mean(axis=1)\nq2_metrics_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create forecast list\nq3_metrics = []\nstore_idx_idx = 0\n\n# Train model, generate and plot forecasts for every TS in q1\nfor ts in q3_list:\n    \n    # Train the model\n    m = Prophet(interval_width=0.95)\n    ts_train = ts[0]\n    ts_test = ts[1]\n    m.fit(ts_train)\n\n    pd.plotting.register_matplotlib_converters()\n    \n    # Get predictions\n    ts_test_forecast = m.predict(ts_test)\n    \n    # Get metrics\n    MAE = mean_absolute_error(ts_test['y'],ts_test_forecast['yhat'])\n    #MASE = mase(ts_test['y'],test_forecast['yhat'])                            \n    MSE = mean_squared_error(ts_test['y'],ts_test_forecast['yhat'])\n    sMAPE = smape(ts_test['y'],ts_test_forecast['yhat'])\n    RMSE = rmse(ts_test['y'],ts_test_forecast['yhat'])\n    NRMSE = nrmse(ts_test['y'],ts_test_forecast['yhat'])\n    \n    # Get store idx\n    store_idx = q3_idxs[store_idx_idx]\n    store_idx_idx= store_idx_idx+1\n    \n    # Store metrics in df\n    prophet_metrics = pd.DataFrame({f'Prophet_store[{store_idx}]': [MSE, sMAPE, RMSE, NRMSE]},\n                      index=['MSE', 'sMAPE', 'RMSE', 'NRMSE'])\n    q3_metrics.append(prophet_metrics)\n    \n    # Plot predictions and observed values\n    pd.plotting.register_matplotlib_converters()\n    \n    ts_test_forecast = m.predict(ts_test)\n    f, ax = plt.subplots(1)\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ax.scatter(ts_test.ds, ts_test['y'], color='r')\n    fig = m.plot(ts_test_forecast, ax=ax)\n    \n    # Zoom in on predicts\n    f, ax = plt.subplots(figsize=(14,5))\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ts_test.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)\n    ts_test_forecast.plot(kind='line',x='ds',y='yhat', color='blue',label='Forecast', ax=ax)\n    plt.title(f'Forecast vs Actuals in Store {store_idx}')\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q3_metrics_df = pd.concat(q3_metrics, axis=1)\nq3_metrics_df['mean'] = q3_metrics_df.mean(axis=1)\nq3_metrics_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create forecast list\nq4_metrics = []\nstore_idx_idx = 0\n\n# Train model, generate and plot forecasts for every TS in q1\nfor ts in q4_list:\n    \n    # Train the model\n    m = Prophet(interval_width=0.95)\n    ts_train = ts[0]\n    ts_test = ts[1]\n    m.fit(ts_train)\n\n    pd.plotting.register_matplotlib_converters()\n    \n    # Get predictions\n    ts_test_forecast = m.predict(ts_test)\n    \n    # Get metrics\n    MAE = mean_absolute_error(ts_test['y'],ts_test_forecast['yhat'])\n    #MASE = mase(ts_test['y'],test_forecast['yhat'])                            \n    MSE = mean_squared_error(ts_test['y'],ts_test_forecast['yhat'])\n    sMAPE = smape(ts_test['y'],ts_test_forecast['yhat'])\n    RMSE = rmse(ts_test['y'],ts_test_forecast['yhat'])\n    NRMSE = nrmse(ts_test['y'],ts_test_forecast['yhat'])\n    \n    # Get store idx\n    store_idx = q4_idxs[store_idx_idx]\n    store_idx_idx= store_idx_idx+1\n    \n    # Store metrics in df\n    prophet_metrics = pd.DataFrame({f'Prophet_store[{store_idx}]': [MSE, sMAPE, RMSE, NRMSE]},\n                      index=['MSE', 'sMAPE', 'RMSE', 'NRMSE'])\n    q4_metrics.append(prophet_metrics)\n    \n    # Plot predictions and observed values\n    pd.plotting.register_matplotlib_converters()\n    \n    ts_test_forecast = m.predict(ts_test)\n    f, ax = plt.subplots(1)\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ax.scatter(ts_test.ds, ts_test['y'], color='r')\n    fig = m.plot(ts_test_forecast, ax=ax)\n    \n    # Zoom in on predicts\n    f, ax = plt.subplots(figsize=(14,5))\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ts_test.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)\n    ts_test_forecast.plot(kind='line',x='ds',y='yhat', color='blue',label='Forecast', ax=ax)\n    plt.title(f'Forecast vs Actuals in Store {store_idx}')\n    plt.show()\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"q4_metrics_df = pd.concat(q4_metrics, axis=1)\nq4_metrics_df['mean'] = q4_metrics_df.mean(axis=1)\nq4_metrics_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Get average metrics for all ts","metadata":{}},{"cell_type":"code","source":"average_prophet_metrics = pd.concat([q1_metrics_df.drop(columns =['mean']),\n                                     q2_metrics_df.drop(columns =['mean']),\n                                     q3_metrics_df.drop(columns =['mean']),\n                                     q4_metrics_df.drop(columns =['mean'])], axis=1)\naverage_prophet_metrics['mean'] = average_prophet_metrics.mean(axis=1)\naverage_prophet_metrics['mean'].head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ts_train = ts_train_list[0]\nts_test = ts_test_list[0]\n\nm = Prophet(interval_width=0.95)\nm.fit(ts_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 10.3.4 - Plot predictions","metadata":{}},{"cell_type":"code","source":"for forecast in q1_forecasts:\n    \n    pd.plotting.register_matplotlib_converters()\n\n    ts_test_forecast = m.predict(ts_test)\n    f, ax = plt.subplots(1)\n    f.set_figheight(5)\n    f.set_figwidth(15)\n    ax.scatter(ts_test.ds, ts_test['y'], color='r')\n    fig = m.plot(ts_test_forecast, ax=ax)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"future = m.make_future_dataframe(periods=48, freq='D')\nforecast = m.predict(future)\n\nforecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n\n#fig = m.plot_components(forecast)\n\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nfig = m.plot(forecast,ax=ax)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 10.3.5 - Compare predictions with actual values","metadata":{}},{"cell_type":"code","source":"\npd.plotting.register_matplotlib_converters()\n\nts_test_forecast = m.predict(ts_test)\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\nax.scatter(ts_test.ds, ts_test['y'], color='r')\nfig = m.plot(ts_test_forecast, ax=ax)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(14,5))\nf.set_figheight(5)\nf.set_figwidth(15)\nts_test.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)\nts_test_forecast.plot(kind='line',x='ds',y='yhat', color='blue',label='Forecast', ax=ax)\nplt.title('Forecast vs Actuals')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\nimport math\n\ndef _naive_forecasting(actual: np.ndarray, seasonality: int = 1):\n    return actual[:-seasonality]\n\ndef smape(actual, predicted):\n    return 100/len(actual) * np.sum(2 * np.abs(predicted - actual) / (np.abs(actual) + np.abs(predicted)))\n\ndef rmse(actual: np.ndarray, predicted: np.ndarray):\n    return np.sqrt(mean_squared_error(actual,predicted))\n\ndef nrmse(actual: np.ndarray, predicted: np.ndarray):\n    return rmse(actual, predicted) / (actual.max() - actual.min())\n\ndef mase(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n    return mae(actual, predicted) / mae(actual[seasonality:], _naive_forecasting(actual, seasonality))\n\nMAE = mean_absolute_error(ts_test['y'],ts_test_forecast['yhat'])\n\n#MASE = mase(ts_test['y'],test_forecast['yhat'])                            \n\nMSE = mean_squared_error(ts_test['y'],ts_test_forecast['yhat'])\nsMAPE = smape(ts_test['y'],ts_test_forecast['yhat'])\nRMSE = rmse(ts_test['y'],ts_test_forecast['yhat'])\nNRMSE = nrmse(ts_test['y'],ts_test_forecast['yhat'])\n\nprophet_metrics = pd.DataFrame({'Prophet': [MSE, sMAPE, RMSE, NRMSE]},\n                  index=['MSE', 'sMAPE', 'RMSE', 'NRMSE'])\n\nprophet_metrics.head()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get metrics for first ts, add RMSE\n\n# Deep AR\nts_deepAR_metrics = item_metrics_deepAR.iloc[0].to_frame()\nts_deepAR_mse = ts_deepAR_metrics.loc[['MSE']].values[0][0]\nts_deepAR_rmse = np.sqrt(ts_deepAR_mse)\ndeepAR_rmse_df = pd.DataFrame([[ts_deepAR_rmse]], index = ['RMSE'])\nts_deepAR_metrics = pd.concat([ts_deepAR_metrics, deepAR_rmse_df])\nts_deepAR_metrics_to_compare = ts_deepAR_metrics.loc[['sMAPE', 'RMSE']]\nts_deepAR_metrics_to_compare.columns = ['Deep AR']\n\n# Simple Feed Forward\nts_SFF_metrics = item_metrics_sff.iloc[0].to_frame()\nts_SFF_mse = ts_SFF_metrics.loc[['MSE']].values[0][0]\nts_SFF_rmse = np.sqrt(ts_SFF_mse)\nSFF_rmse_df = pd.DataFrame([[ts_SFF_rmse]], index = ['RMSE'])\nts_SFF_metrics = pd.concat([ts_SFF_metrics, SFF_rmse_df])\nts_SFF_metrics_to_compare = ts_SFF_metrics.loc[['sMAPE', 'RMSE']]\nts_SFF_metrics_to_compare.columns = ['Simple Feed Forward']\n\n# Naive Seasonal\nts_seasonal_metrics = item_metrics_seasonal.iloc[0].to_frame()\nts_seasonal_mse = ts_seasonal_metrics.loc[['MSE']].values[0][0]\nts_seasonal_rmse = np.sqrt(ts_seasonal_mse)\nseasonal_rmse_df = pd.DataFrame([[ts_seasonal_rmse]], index = ['RMSE'])\nts_seasonal_metrics = pd.concat([ts_seasonal_metrics, seasonal_rmse_df])\nts_seasonal_metrics_to_compare = ts_seasonal_metrics.loc[['sMAPE', 'RMSE']]\nts_seasonal_metrics_to_compare.columns = ['Seasonal Naive']\n\n# Join with prophet metrics on common metrics\nts_prophet_metrics_to_compare = prophet_metrics.loc[['sMAPE', 'RMSE']]\n\n# Show comparisons\nts_metrics = pd.concat([ts_deepAR_metrics_to_compare, ts_SFF_metrics_to_compare, ts_seasonal_metrics_to_compare, ts_prophet_metrics_to_compare], axis=1)\nts_metrics\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 10.3.2 - Cross Validation","metadata":{}},{"cell_type":"code","source":"from fbprophet.diagnostics import cross_validation\ndf_cv = cross_validation(m, initial='500 days', period='48 days', horizon = '48 days')\ndf_cv.head()\n\nfrom fbprophet.diagnostics import performance_metrics\ndf_p = performance_metrics(df_cv)\ndf_p.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 10.3.3 - Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"import itertools\nimport numpy as np\nimport pandas as pd\n\nparam_grid = {  \n    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n}\n\n# Generate all combinations of parameters\nall_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\nrmses = []  # Store the RMSEs for each params here\n\n# Use cross validation to evaluate all parameters\nfor params in all_params:\n    m = Prophet(**params).fit(ts)  # Fit model with given params\n    df_cv = cross_validation(m, initial='500 days', period='48 days', horizon = '48 days')\n    df_p = performance_metrics(df_cv, rolling_window=1)\n    rmses.append(df_p['rmse'].values[0])\n\n# Find the best parameters\ntuning_results = pd.DataFrame(all_params)\ntuning_results['rmse'] = rmses\nprint(tuning_results)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_params = all_params[np.argmin(rmses)]\nprint(best_params)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"agg_metrics_prophet, item_metrics_prophet = evaluator(iter(tss), iter(forecasts), num_series=len(test_ds))\n\ndf_metrics = pd.DataFrame.join(\n    df_metrics,\n    pd.DataFrame.from_dict(agg_metrics_prophet, orient='index').rename(columns={0: \"Prophet\"})\n)\ndf_metrics.loc[[\"MASE\",\"MAPE\", \"MSIS\", \"sMAPE\", \"RMSE\", \"NRMSE\", \"MRMSSE\", \"ND\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12. Train traditional models for comparison\n* Holt Winter's Seasonal Method (additive)\n* Seasonal Auto-Regressive Integrated Moving Average\n\n### 12.1 - Holt Winter's Seasonal Method (additive)","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.tsa.api import ExponentialSmoothing\n\ndef holt_win_sea(y,y_to_train,y_to_test,seasonal_type,seasonal_period,predict_date):\n    \n    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n    \n    if seasonal_type == 'additive':\n        fit1 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add').fit(use_boxcox=True)\n        fcast1 = fit1.forecast(predict_date).rename('Additive')\n        mse1 = ((fcast1 - y_to_test) ** 2).mean()\n        print('The Root Mean Squared Error of additive trend, additive seasonal of '+ \n              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse1), 2)))\n        \n        fit2 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add', damped=True).fit(use_boxcox=True)\n        fcast2 = fit2.forecast(predict_date).rename('Additive+damped')\n        mse2 = ((fcast2 - y_to_test) ** 2).mean()\n        print('The Root Mean Squared Error of additive damped trend, additive seasonal of '+ \n              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse2), 2)))\n        \n        fit1.fittedvalues.plot(style='--', color='red')\n        fcast1.plot(style='--', marker='o', color='red', legend=True)\n        fit2.fittedvalues.plot(style='--', color='green')\n        fcast2.plot(style='--', marker='o', color='green', legend=True)\n    \n    elif seasonal_type == 'multiplicative':  \n        fit3 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul').fit(use_boxcox=True)\n        fcast3 = fit3.forecast(predict_date).rename('Multiplicative')\n        mse3 = ((fcast3 - y_to_test) ** 2).mean()\n        print('The Root Mean Squared Error of additive trend, multiplicative seasonal of '+ \n              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse3), 2)))\n        \n        fit4 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul', damped=True).fit(use_boxcox=True)\n        fcast4 = fit4.forecast(predict_date).rename('Multiplicative+damped')\n        mse4 = ((fcast3 - y_to_test) ** 2).mean()\n        print('The Root Mean Squared Error of additive damped trend, multiplicative seasonal of '+ \n              'period season_length={} and a Box-Cox transformation {}'.format(seasonal_period,round(np.sqrt(mse4), 2)))\n        \n        fit3.fittedvalues.plot(style='--', color='red')\n        fcast3.plot(style='--', marker='o', color='red', legend=True)\n        fit4.fittedvalues.plot(style='--', color='green')\n        fcast4.plot(style='--', marker='o', color='green', legend=True)\n        \n    else:\n        print('Wrong Seasonal Type. Please choose between additive and multiplicative')\n\n    plt.show()\n\nseasonality_frequency = 28\n    \nholt_win_sea(ts_target_values, ts_train_values, ts_test_values,'additive',52, prediction_length)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 12.2 - Season Auto-Regressive Integrated Moving Average (SARIMA)\n#### In order to get the best prediction, its important to find the values of SARIMA(p,d,q)(P,D,Q)m that optimize a metric of interest. We will use a \"grid search\" to iteratively explore different combinations of parameters. ","metadata":{}},{"cell_type":"code","source":"import itertools\n\ndef sarima_grid_search(y,seasonal_period):\n    p = d = q = range(0, 2)\n    pdq = list(itertools.product(p, d, q))\n    seasonal_pdq = [(x[0], x[1], x[2],seasonal_period) for x in list(itertools.product(p, d, q))]\n    \n    mini = float('+inf')\n    \n    \n    for param in pdq:\n        for param_seasonal in seasonal_pdq:\n            try:\n                mod = sm.tsa.statespace.SARIMAX(y,\n                                                order=param,\n                                                seasonal_order=param_seasonal,\n                                                enforce_stationarity=False,\n                                                enforce_invertibility=False)\n\n                results = mod.fit()\n                \n                if results.aic < mini:\n                    mini = results.aic\n                    param_mini = param\n                    param_seasonal_mini = param_seasonal\n\n#                 print('SARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results.aic))\n            except:\n                continue\n    print('The set of parameters with the minimum AIC is: SARIMA{}x{} - AIC:{}'.format(param_mini, param_seasonal_mini, mini))\n    \nsarima_grid_search(ts_target_values,seasonality_frequency)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Call this function after pick the right(p,d,q) for SARIMA based on AIC               \ndef sarima_eva(y,order,seasonal_order,seasonal_period,pred_date,y_to_test):\n    # fit the model \n    mod = sm.tsa.statespace.SARIMAX(y,\n                                order=order,\n                                seasonal_order=seasonal_order,\n                                enforce_stationarity=False,\n                                enforce_invertibility=False)\n\n    results = mod.fit()\n    print(results.summary().tables[1])\n    \n    results.plot_diagnostics(figsize=(16, 8))\n    plt.show()\n    \n    # The dynamic=False argument ensures that we produce one-step ahead forecasts, \n    # meaning that forecasts at each point are generated using the full history up to that point.\n    pred = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=False)\n    pred_ci = pred.conf_int()\n    y_forecasted = pred.predicted_mean\n    mse = ((y_forecasted - y_to_test) ** 2).mean()\n    print('The Root Mean Squared Error of SARIMA with season_length={} and dynamic = False {}'.format(seasonal_period,round(np.sqrt(mse), 2)))\n\n    ax = y.plot(label='observed')\n    y_forecasted.plot(ax=ax, label='One-step ahead Forecast', alpha=.7, figsize=(14, 7))\n    ax.fill_between(pred_ci.index,\n                    pred_ci.iloc[:, 0],\n                    pred_ci.iloc[:, 1], color='k', alpha=.2)\n\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sessions')\n    plt.legend()\n    plt.show()\n\n    # A better representation of our true predictive power can be obtained using dynamic forecasts. \n    # In this case, we only use information from the time series up to a certain point, \n    # and after that, forecasts are generated using values from previous forecasted time points.\n    pred_dynamic = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=True, full_results=True)\n    pred_dynamic_ci = pred_dynamic.conf_int()\n    y_forecasted_dynamic = pred_dynamic.predicted_mean\n    mse_dynamic = ((y_forecasted_dynamic - y_to_test) ** 2).mean()\n    print('The Root Mean Squared Error of SARIMA with season_length={} and dynamic = True {}'.format(seasonal_period,round(np.sqrt(mse_dynamic), 2)))\n\n    ax = y.plot(label='observed')\n    y_forecasted_dynamic.plot(label='Dynamic Forecast', ax=ax,figsize=(14, 7))\n    ax.fill_between(pred_dynamic_ci.index,\n                    pred_dynamic_ci.iloc[:, 0],\n                    pred_dynamic_ci.iloc[:, 1], color='k', alpha=.2)\n\n    ax.set_xlabel('Date')\n    ax.set_ylabel('Sessions')\n\n    plt.legend()\n    plt.show()\n    \n    return (results)\n\nsarima_eva(ts_target_values,(1, 1, 1),(1, 1, 0, seasonality_frequency),seasonality_frequency,'2019-06-02',ts_test_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}